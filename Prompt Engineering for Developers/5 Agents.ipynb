{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c13c622c-4698-436f-9e04-73a277e55800",
   "metadata": {},
   "source": [
    "## LangChain: Agents\n",
    "\n",
    "An Agent is a wrapper around a model, which takes in user input and returns a response corresponding to an “action” to take and a corresponding “action input”.\n",
    "\n",
    "Some applications will require not just a predetermined chain of calls to LLMs/other tools, but potentially an unknown chain that depends onthe user's input. In these types of chains, there is \"agent\" which has access to a suite of tools. Depending on the user input, the agent can then decide which, if any, of these tools to call.\n",
    "\n",
    "- **TOOLS**: How language models interact with other resources.\n",
    "- **AGENTS**: The language model that drives decision making.\n",
    "- **ATOOLKITS**: Sets of tools that when used together can accomplish a specific task.\n",
    "- **AGENT EXECUTOR**: The logic for running agents with tools.\n",
    "\n",
    "NOTE: Sometimes you can think of LLM models as a reasoning engine in which you can give chunks fo text or other sources of text or information, and then the LLM will maybe use this background knowledge that's learned off the internet to use the new information you give it to help you answer questions or reason through content or decide even what do no next. And that is where LangChain Agents framework helps you to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ffd379-2a7a-46ed-b1af-5694ac4de717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe3a38e7-ebc3-41f8-b6dd-15493e6a032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_KEY = os.getenv('OPENAI_KEY')\n",
    "openai.api_key = OPENAI_KEY\n",
    "\n",
    "LLM_MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d41b92d0-c158-41d9-bcc6-32394db7dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b47101-669e-43cf-ac29-b957ff818b07",
   "metadata": {},
   "source": [
    "#### Built-in LangChain tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450f307c-c66d-49ed-9ded-6ed23673920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=LLM_MODEL, openai_api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b4c7c8-67d0-4627-a492-8839090ca568",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\", \"wikipedia\"], llm=llm)\n",
    "\n",
    "# NOTE: llm-math tool is a chain itself, it is a language model in conjuction with a calculator.\n",
    "#       wikipedia is a language tool, that connects to the wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a461c0f1-dcaf-46ae-a5d5-d6b3d1498c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, handle_parsing_errors=True, verbose=True,\n",
    ")\n",
    "\n",
    "# CHAT_ZERO_SHOT_REACT_DESCRIPTION: it is an agent optimized to work with chat models, it is a prompting \n",
    "# technique designed to work best with best reasoning techniques to get the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aa9ca90-4314-499f-a55f-3c3bb891716a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can use the calculator tool to find the answer to this question.\n",
      "\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"25% of 300\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 75.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe answer is 75.0.\n",
      "Final Answer: 75.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the 25% of 300?', 'output': '75.0'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"What is the 25% of 300?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53ec5f-29f7-44c0-a63d-54777d00145c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5e135-4a43-4bbf-93b0-bc544357cc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
