{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc4930e5-a7d3-418f-ba05-c456df764846",
   "metadata": {},
   "source": [
    "## Use Cases\n",
    "Different end-to-end use cases that LangChain can help with. For each use case, we not only motivate the use case but also discuss which components are most helpful for solving that use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97faa8a-d53c-4366-9056-331959e0c2fd",
   "metadata": {},
   "source": [
    "### Personal Assistants\n",
    "Personal assistants are a perfect application to build because they combine both of the core value props of LangChain (action taking and personalized data). In order to build a personal assistant you should understand the following concepts:\n",
    "1. `PromptTemplate` - this will guide how your personal assistant acts. Are they sassy? Helpful? These can be used to give your personal assistant some character.\n",
    "2. `Memory` - your personal assistant should probably remember things. They should definitely be able to hold a conversation (short term memory) and they should probably have some concept of long term memory as well.\n",
    "3. `Tools` - your personal assistant will be differentiated by the tools you give it. What should it know how to do?\n",
    "4. `Agent` - your personal assistant will have to understand what actions it should take. Constructing the best agent possible will be important.\n",
    "5. `Agent Executor` - after you've got your tools and your agent, in order to put it into practice you'll need to set up an environment for the agent to use those tools. This is where the Agent Executor comes into play."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d15367-294f-411b-bf1c-4eda00caf88d",
   "metadata": {},
   "source": [
    "### Question Answering Over Documents\n",
    "Although LLMs are powerful, they do not know about information they were not trained on. If you want to use an LLM to answer questions about documents it was not trained on, you have to give it information about those documents. The most common way to do this is through \"retrieval augmented generation\" (RAG).\n",
    "\n",
    "The idea of retrieval augmented generation is that when given a question you first do a retrieval step to fetch any relevant documents. You then pass those documents, along with the original question, to the language model and have it generate a response. In order to do this, however, you first have to have your documents in a format where they can be queried in such a manner. This page goes over the high level ideas between those two steps: (1) ingestion of documents into a queriable format, and then (2) the retrieval augmented generation chain.\n",
    "\n",
    "- **Ingestion** - In order use a language model to interact with your data, you first have to get in a suitable format. That format would be an Index. By putting data into an Index, you make it easy for any downstream steps to interact with it. There are several types of indexes, but by far the most common one is a Vectorstore. Ingesting documents into a vectorstore can be done with the following steps:\n",
    "  1. Load documents (using a Document Loader)\n",
    "  2. Split documents (using a Text Splitter)\n",
    "  3. Create embeddings for documents (using a Text Embedding Model)\n",
    "  4. Store documents and embeddings in a vectorstore\n",
    "\n",
    "- **Generation** - Now that we have an Index, how do we use this to do generation? This can be broken into the following steps:\n",
    "  1. Receive user question\n",
    "  2. Lookup documents in the index relevant to the question\n",
    "  3. Construct a PromptValue from the question and any relevant documents (using a PromptTemplate).\n",
    "  4. Pass the PromptValue to a model\n",
    "  5. Get back the result and return to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e821c-1986-48d9-bbdc-5ff28b2cfe28",
   "metadata": {},
   "source": [
    "### Chatbots (ChatGPT)\n",
    "ChatGPT took the world by storm by exposing a powerful language model with a new interface - chat. There are several components that go into building a chatbot.\n",
    "1. **The model** - you can construct a chatbot from a normal language model or a Chat Model. The important thing to remember is that even if you are using a Chat Model, the API itself is stateless, meaning it won't remember previous interactions - you have to pass them in.\n",
    "2. **PromptTemplate** - this will guide how your chatbot acts. Are they sassy? Helpful? These can be used to give your chatbot some character.\n",
    "3. **Memory** - as mentioned above, the models themselves are stateless. Memory brings some concept of state to the table, allowing it remember previous interactions\n",
    "\n",
    "Chatbots are often very powerful and more differentiated when combined with other sources of data. The same techniques that underpin \"Question Answering Over Docs\" can also be used here to give your chatbot access to that data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8acd65-f710-4162-bd32-fa7cb7617929",
   "metadata": {},
   "source": [
    "### Querying Tabular Data\n",
    "Lots of data and information is stored in tabular data, whether it be csvs, excel sheets, or SQL tables. This page covers all resources available in LangChain for working with data in this format.\n",
    "- **Document Loading** - If you have text data stored in a tabular format, you may want to load the data into a Document and then index it as you would other text/unstructured data. For this, you should use a document loader like the CSVLoader and then you should create an Index over that data, and query it that way.\n",
    "- **Querying** - If you have more numeric tabular data, or have a large amount of data and don't want to index it, you can also use a language model to interact with it directly.\n",
    "  - **Chains** - If you are just getting started, and you have relatively small/simple tabular data, you should get started with chains. Chains are a sequence of predetermined steps, so they are good to get started with as they give you more control and let you understand what is happening better.\n",
    "  - **Agents** - Agents are more complex, and involve multiple queries to the LLM to understand what to do. The downside of agents are that you have less control. The upside is that they are more powerful, which allows you to use them on larger databases and more complex schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a376e9-962c-4bb8-9644-df13ad60f885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723f4a4-8c07-44bf-9e54-d2527ccf81a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2ecf6-5ef4-487c-8a97-841143471be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
