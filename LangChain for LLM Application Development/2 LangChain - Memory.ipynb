{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49282fa8-ac65-4801-b12f-2ea93c99af52",
   "metadata": {},
   "source": [
    "## LangChain: Memory\n",
    "\n",
    "When you interact with these models, they don't remember what you say before or any of the previous conversation, which is an issue when you are building some applications like chatbot and you want to have conversation with them. In this section we'll cover memory, which is basically how do you remember previous parts of the conversation and feed that into the language model so that they can have this conversational flow as you're interacting with them.\n",
    "\n",
    "LangChain offers multiple sophisticated options of managing these memories. Let's jump in and take a look.\n",
    "\n",
    "### Outline\n",
    "- `ConversationBufferMemory`\n",
    "- `ConversationBufferWindowMemory`\n",
    "- `ConversationTokenBuffermemory`\n",
    "- `ConversationSummaryMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3c39d8-fb00-4c39-9a92-dff7de557277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_KEY = os.getenv('OPENAI_KEY')\n",
    "openai.api_key = OPENAI_KEY\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32e834c-c605-4d66-8402-3a0cbca63c37",
   "metadata": {},
   "source": [
    "#### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d757dca3-e615-42eb-9d3c-3e1cc188f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\", openai_api_key=OPENAI_KEY)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, memory=memory, verbose=True # verbose: True will show what the langchain is doing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd8e770-0e55-4204-82cd-34408bef0273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, My name is Mrinal Sinha\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Mrinal Sinha! How can I assist you today?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, My name is Mrinal Sinha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84c1f71b-3959-4d3c-842d-98ef70a290c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, My name is Mrinal Sinha\n",
      "AI: Hello Mrinal Sinha! How can I assist you today?\n",
      "Human: What is 1+1\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5330d7fb-13aa-4fd2-9962-437110bc5d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, My name is Mrinal Sinha\n",
      "AI: Hello Mrinal Sinha! How can I assist you today?\n",
      "Human: What is 1+1\n",
      "AI: 1+1 is equal to 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Mrinal Sinha.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20a1d464-e33e-4563-89bc-bc9a16d466b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Hi, My name is Mrinal Sinha\\nAI: Hello Mrinal Sinha! How can I assist you today?\\nHuman: What is 1+1\\nAI: 1+1 is equal to 2.\\nHuman: What is my name?\\nAI: Your name is Mrinal Sinha.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f80ee079-e13b-43ca-85fc-0ba94102410b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi, My name is Mrinal Sinha\\nAI: Hello Mrinal Sinha! How can I assist you today?\\nHuman: What is 1+1\\nAI: 1+1 is equal to 2.\\nHuman: What is my name?\\nAI: Your name is Mrinal Sinha.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d022bb09-77a9-419b-846a-299698145368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n",
      "{'history': \"Human: Hi\\nAI: What's up\"}\n"
     ]
    }
   ],
   "source": [
    "# You can save custom context in the memory\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})\n",
    "print(memory.buffer)\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d5605-e054-4fb8-aaeb-dba9d1b066e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
