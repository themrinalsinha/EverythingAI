{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cba54d8-a354-43d2-bd28-cd8aed6ecb40",
   "metadata": {},
   "source": [
    "## LangChain: Chains\n",
    "It is one of the most important key building block of LangChain, namely the `Chain`. The chain usually combines an LLM (Large Language Model) together with a prompt and with this building block, and you can put bunch of these building blocks together to carry out a sequence of operations on your text or your other data. \n",
    "\n",
    "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components.\n",
    "\n",
    "LangChain provides the Chain interface for such \"chained\" applications. We define a Chain very generically as a sequence of calls to components, which can include other chains.\n",
    "\n",
    "### Outline\n",
    "- LLMChain\n",
    "- Sequential Chains\n",
    "  - SimpleSequentialChain\n",
    "  - SequentialChain\n",
    "- Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83bbbe1-df95-43cd-b5c7-9ac7b1ab0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_KEY = os.getenv('OPENAI_KEY')\n",
    "openai.api_key = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94fde3cb-e926-4e15-a3e5-83b6e39bdabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n  Â I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b162559b-0980-49b7-8895-7e32ee4fb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\", openai_api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d00c46-a132-4d6a-8c2c-e43bbf2cf5fd",
   "metadata": {},
   "source": [
    "#### LLMChain\n",
    "A LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdc7de0-12c7-4051-9d4b-a99615d1b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69f3275b-b976-4a93-a325-637992a01a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Royal Comfort Linens\"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "product = \"Qeen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c9653b-4d13-465f-b85c-6c5684ae5ab7",
   "metadata": {},
   "source": [
    "#### Sequential Chains\n",
    "The next step after calling a language model is to make a series of calls to a language model. This is particularly useful when you want to take the output from one call and use it as the input to another.\n",
    "\n",
    "It is another type of chains. The idea is to combine multiple chains where the output of the once chain is the input of the next chain.\n",
    "There is two types of sequential chains:\n",
    "1. SimpleSequentialChain: Single input/output\n",
    "2. SequentialChain: multiple inputs/outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d785679-072d-4810-8b08-80533ba26bda",
   "metadata": {},
   "source": [
    "#### 1. SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "960fdfb3-b1f6-4b2e-b4f5-80d85367f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "362f3faf-7f54-4a35-9a87-bee2409fb8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2181daa9-1b83-4ea5-9361-91cb1742c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a27b8656-4b6e-4444-bb14-6185fb929700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRoyal Comfort Linens\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mRoyal Comfort Linens is a high-quality bedding and linen company that offers luxurious and comfortable products for a peaceful sleep.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Royal Comfort Linens is a high-quality bedding and linen company that offers luxurious and comfortable products for a peaceful sleep.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b08b48-a1a5-4f4c-842c-d3cad5fe8ed6",
   "metadata": {},
   "source": [
    "#### 2. SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "688c7a26-1eda-4ff4-963c-626c1da4944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n",
    "\n",
    "\n",
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n",
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3799b01-8d3d-4ec0-8980-8229e0ecc8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "364dc940-4bfd-411c-8730-bc134c1a4b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfd01c73-a9af-4a2e-8c21-4176bf008467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\",\n",
       " 'English_Review': \"I find the taste mediocre. The foam doesn't hold, it's weird. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\",\n",
       " 'summary': 'The reviewer is disappointed with the taste and foam quality of the product, suspecting that it may be an old batch or counterfeit compared to the ones bought in stores.',\n",
       " 'followup_message': \"Cher(e) client(e),\\n\\nNous vous remercions sincÃ¨rement d'avoir partagÃ© votre expÃ©rience avec notre produit. Nous sommes vraiment dÃ©solÃ©s d'apprendre que vous avez Ã©tÃ© dÃ©Ã§u(e) par le goÃ»t et la qualitÃ© de la mousse de notre produit.\\n\\nNous tenons Ã  vous assurer que nous prenons trÃ¨s au sÃ©rieux vos prÃ©occupations et que nous souhaitons rÃ©soudre ce problÃ¨me rapidement. Nous enquÃªtons actuellement sur la situation afin de dÃ©terminer si cela est dÃ» Ã  un lot pÃ©rimÃ© ou Ã  une contrefaÃ§on.\\n\\nLa satisfaction de nos clients est notre principale prioritÃ© et nous travaillons constamment Ã  amÃ©liorer la qualitÃ© de nos produits. Votre avis nous aide Ã  identifier les problÃ¨mes et Ã  y remÃ©dier.\\n\\nNous vous prions de bien vouloir nous contacter directement avec plus de dÃ©tails, tels que la date d'achat et le lieu d'achat, afin que nous puissions enquÃªter plus en profondeur sur cette situation. Nous voulons nous assurer que vous puissiez profiter pleinement de notre produit conforme Ã  nos normes de qualitÃ©.\\n\\nEncore une fois, nous vous prions de nous excuser pour cette expÃ©rience dÃ©cevante et nous vous remercions de votre confiance. Nous nous engageons Ã  faire tout notre possible pour rÃ©soudre ce problÃ¨me.\\n\\nCordialement,\\n\\nL'Ã©quipe de [Votre Entreprise]\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b8ee00-ffb0-4d17-9486-1876c2e4844a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c99b3b-3ec3-4237-af6a-2b370ea57818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc19a0-61f9-44ea-b3cf-6e47e9de88ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
