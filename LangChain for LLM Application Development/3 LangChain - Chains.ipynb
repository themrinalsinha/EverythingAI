{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cba54d8-a354-43d2-bd28-cd8aed6ecb40",
   "metadata": {},
   "source": [
    "## LangChain: Chains\n",
    "It is one of the most important key building block of LangChain, namely the `Chain`. The chain usually combines an LLM (Large Language Model) together with a prompt and with this building block, and you can put bunch of these building blocks together to carry out a sequence of operations on your text or your other data. \n",
    "\n",
    "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components.\n",
    "\n",
    "LangChain provides the Chain interface for such \"chained\" applications. We define a Chain very generically as a sequence of calls to components, which can include other chains.\n",
    "\n",
    "### Outline\n",
    "- LLMChain\n",
    "- Sequential Chains\n",
    "  - SimpleSequentialChain\n",
    "  - SequentialChain\n",
    "- Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83bbbe1-df95-43cd-b5c7-9ac7b1ab0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_KEY = os.getenv('OPENAI_KEY')\n",
    "openai.api_key = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94fde3cb-e926-4e15-a3e5-83b6e39bdabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b162559b-0980-49b7-8895-7e32ee4fb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\", openai_api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d00c46-a132-4d6a-8c2c-e43bbf2cf5fd",
   "metadata": {},
   "source": [
    "#### LLMChain\n",
    "A LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdc7de0-12c7-4051-9d4b-a99615d1b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69f3275b-b976-4a93-a325-637992a01a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Royal Comfort Linens\"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "product = \"Qeen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c9653b-4d13-465f-b85c-6c5684ae5ab7",
   "metadata": {},
   "source": [
    "#### Sequential Chains\n",
    "The next step after calling a language model is to make a series of calls to a language model. This is particularly useful when you want to take the output from one call and use it as the input to another.\n",
    "\n",
    "It is another type of chains. The idea is to combine multiple chains where the output of the once chain is the input of the next chain.\n",
    "There is two types of sequential chains:\n",
    "1. SimpleSequentialChain: Single input/output\n",
    "2. SequentialChain: multiple inputs/outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d785679-072d-4810-8b08-80533ba26bda",
   "metadata": {},
   "source": [
    "#### 1. SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "960fdfb3-b1f6-4b2e-b4f5-80d85367f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "362f3faf-7f54-4a35-9a87-bee2409fb8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2181daa9-1b83-4ea5-9361-91cb1742c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a27b8656-4b6e-4444-bb14-6185fb929700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRoyal Comfort Linens\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mRoyal Comfort Linens is a high-quality bedding and linen company that offers luxurious and comfortable products for a peaceful sleep.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Royal Comfort Linens is a high-quality bedding and linen company that offers luxurious and comfortable products for a peaceful sleep.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b08b48-a1a5-4f4c-842c-d3cad5fe8ed6",
   "metadata": {},
   "source": [
    "#### 2. SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "688c7a26-1eda-4ff4-963c-626c1da4944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n",
    "\n",
    "\n",
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n",
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3799b01-8d3d-4ec0-8980-8229e0ecc8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "364dc940-4bfd-411c-8730-bc134c1a4b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfd01c73-a9af-4a2e-8c21-4176bf008467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n",
       " 'English_Review': \"I find the taste mediocre. The foam doesn't hold, it's weird. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\",\n",
       " 'summary': 'The reviewer is disappointed with the taste and foam quality of the product, suspecting that it may be an old batch or counterfeit compared to the ones bought in stores.',\n",
       " 'followup_message': \"Cher(e) client(e),\\n\\nNous vous remercions sincèrement d'avoir partagé votre expérience avec notre produit. Nous sommes vraiment désolés d'apprendre que vous avez été déçu(e) par le goût et la qualité de la mousse de notre produit.\\n\\nNous tenons à vous assurer que nous prenons très au sérieux vos préoccupations et que nous souhaitons résoudre ce problème rapidement. Nous enquêtons actuellement sur la situation afin de déterminer si cela est dû à un lot périmé ou à une contrefaçon.\\n\\nLa satisfaction de nos clients est notre principale priorité et nous travaillons constamment à améliorer la qualité de nos produits. Votre avis nous aide à identifier les problèmes et à y remédier.\\n\\nNous vous prions de bien vouloir nous contacter directement avec plus de détails, tels que la date d'achat et le lieu d'achat, afin que nous puissions enquêter plus en profondeur sur cette situation. Nous voulons nous assurer que vous puissiez profiter pleinement de notre produit conforme à nos normes de qualité.\\n\\nEncore une fois, nous vous prions de nous excuser pour cette expérience décevante et nous vous remercions de votre confiance. Nous nous engageons à faire tout notre possible pour résoudre ce problème.\\n\\nCordialement,\\n\\nL'équipe de [Votre Entreprise]\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b8ee00-ffb0-4d17-9486-1876c2e4844a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c99b3b-3ec3-4237-af6a-2b370ea57818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc19a0-61f9-44ea-b3cf-6e47e9de88ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
